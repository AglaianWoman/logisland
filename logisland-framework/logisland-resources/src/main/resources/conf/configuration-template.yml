#########################################################################################################
# Logisland configuration script tempate
#########################################################################################################

version: 0.9.5
documentation: LogIsland analytics main config file. Put here every engine or component config

#########################################################################################################
# engine
engine:
  component: com.hurence.logisland.engine.spark.SparkStreamProcessingEngine
  type: engine
  documentation: Main Logisland job entry point
  configuration:
    spark.master: yarn-cluster
    spark.driver.memory: 512m
    spark.driver.cores: 1
    spark.executor.memory: 1500m
    spark.executor.cores: 2
    spark.executor.instances: 10
    spark.appName: FdjIndexing
    spark.streaming.batchDuration: 10000
    spark.serializer: org.apache.spark.serializer.KryoSerializer
    spark.streaming.backpressure.enabled: true
    spark.streaming.unpersist: false
    spark.streaming.blockInterval: 500
    spark.streaming.kafka.maxRatePerPartition: 6000
    spark.streaming.timeout: -1
    spark.ui.port: 4050
  processorChains:

    # parsing
    - processorChain: parsing_stream
      component: com.hurence.logisland.processor.chain.KafkaRecordStream
      type: stream
      documentation: a processor that links
      configuration:
        kafka.input.topics: logisland_raw
        kafka.output.topics: logisland_events
        kafka.error.topics: logisland_errors
        kafka.input.topics.serializer: com.hurence.logisland.serializer.KryoRecordSerializer
        kafka.output.topics.serializer: com.hurence.logisland.serializer.KryoRecordSerializer
        kafka.error.topics.serializer: com.hurence.logisland.serializer.JsonRecordSerializer
        kafka.metadata.broker.list: sd-79372:6667,sd-84190:6667,sd-84191:6667,sd-84192:6667,sd-84196:6667
        kafka.zookeeper.quorum: sd-76387:2181,sd-84186:2181,sd-84189:2181
        kafka.topic.autoCreate: true
        kafka.topic.default.partitions: 10
        kafka.topic.default.replicationFactor: 1
      processors:

        # Generate random events based on an avro schema
        - processor: sample_regex_parser
          component: com.hurence.logisland.processor.SplitText
          type: parser
          documentation: a parser that produce events from a REGEX
          configuration:
            key.regex: (\S*):(\S*)
            key.fields: c,d
            value.regex: (\S*):(\S*)
            value.fields: a,b

    # indexing
    - processorChain: indexing_stream
      component: com.hurence.logisland.processor.chain.KafkaRecordStream
      type: processor
      documentation: a processor that push events to ES
      configuration:
        kafka.input.topics: logisland_events
        kafka.output.topics: logisland_trash
        kafka.error.topics: logisland_errors
        kafka.input.topics.serializer: com.hurence.logisland.serializer.KryoRecordSerializer
        kafka.output.topics.serializer: com.hurence.logisland.serializer.KryoRecordSerializer
        kafka.error.topics.serializer: com.hurence.logisland.serializer.JsonRecordSerializer
        kafka.metadata.broker.list: sd-79372:6667,sd-84190:6667,sd-84191:6667,sd-84192:6667,sd-84196:6667
        kafka.zookeeper.quorum: sd-76387:2181,sd-84186:2181,sd-84189:2181
        kafka.topic.autoCreate: true
        kafka.topic.default.partitions: 10
        kafka.topic.default.replicationFactor: 1
      processors:

        # split text on a regex
        - processor: sample_regex_parser
          component: com.hurence.logisland.processor.SplitText
          type: parser
          documentation: a parser that produce events from a REGEX
          configuration:
            key.regex: (\S*):(\S*)
            key.fields: c,d
            value.regex: (\S*):(\S*)
            value.fields: a,b

        # put to elasticsearch
        - processor: es_publisher
          component: com.hurence.logisland.processor.elasticsearch.PutElasticsearch
          type: processor
          documentation: a processor that trace the processed events
          configuration:
            default.index: loterie
            default.type: event
            hosts: sd-84186:9300,sd-84192:9300,sd-84196:9300,sd-84191:9300,sd-84190:9300
            cluster.name: elastic-hurence
            batch.size: 8000
            timebased.index: yesterday
            es.index.field: search_index
            es.type.field: event_type

