version: 0.1
documentation: LogIsland analytics main config file. Put here every engine or component config

components:
  # Main event streaming engine
  - component: com.hurence.logisland.engine.SparkStreamProcessingEngine
    type: engine
    version: 0.1.0
    documentation: Main Logisland job entry point
    configuration:
      spark.master: local[8]
      spark.executorMemory: 4g
      spark.checkpointingDirectory: file:///tmp
      spark.appName: My first stream component
      spark.streaming.batchDuration: 2000
      spark.serializer: org.apache.spark.serializer.KryoSerializer
      spark.streaming.backpressure.enabled: true
      spark.streaming.unpersist: false
      spark.streaming.blockInterval: 350
      spark.streaming.kafka.maxRatePerPartition: 500
      spark.streaming.timeout: 20000
      spark.ui.port: 4050
      kafka.metadata.broker.list: localhost:9092
      kafka.zookeeper.quorum: localhost:2181
      output.event.serializer: com.hurence.logisland.serializer.EventKryoSerializer
      input.event.serializer: com.hurence.logisland.serializer.EventKryoSerializer

  # A Debug component that only logs what it reads
  - component: com.hurence.logisland.processor.debug.EventDebuggerProcessor
    type: processor
    version: 0.1.0
    documentation: a processor that trace the processed events
    configuration:
      kafka.input.topics: logisland-mock-out
      kafka.output.topics: none
      kafka.error.topics: none


  # Generate random events based on an avro schema
  - component: com.hurence.logisland.processor.parser.SplitText
    type: parser
    version: 0.1.0
    documentation: a parser that produce events from a REGEX
    configuration:
      kafka.input.topics: logisland-mock-in
      kafka.output.topics: logisland-mock-out
      kafka.error.topics: logisland-error
      event.type: log_traker
      value.regex: (\S*):(\S*)
      value.fields: a,b
      key.regex: (\S*):(\S*)
      key.fields: c,d

