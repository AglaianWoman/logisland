version: 0.1
documentation: LogIsland analytics main config file. Put here every engine or component config

components:
  # Main event streaming engine
  - component: com.hurence.logisland.engine.SparkStreamProcessingEngine
    type: engine
    version: 0.1.0
    documentation: Main Logisland job entry point
    configuration:
      spark.master: local[8]
      spark.executorMemory: 4g
      spark.checkpointingDirectory: file:///tmp
      spark.appName: Apache
      spark.streaming.batchDuration: 2000
      spark.serializer: org.apache.spark.serializer.KryoSerializer
      spark.streaming.backpressure.enabled: true
      spark.streaming.unpersist: false
      spark.streaming.blockInterval: 350
      spark.streaming.kafka.maxRatePerPartition: 500
      spark.streaming.timeout: -1
      spark.ui.port: 4050
      kafka.metadata.broker.list: localhost:9092
      kafka.zookeeper.quorum: localhost:2181
      output.event.serializer: com.hurence.logisland.serializer.EventKryoSerializer
      input.event.serializer: com.hurence.logisland.serializer.EventKryoSerializer


  # An elasticsearc compo
  - component: com.hurence.logisland.processor.elasticsearch.PutElasticsearch
    type: processor
    version: 0.1.0
    documentation: a processor that trace the processed events
    configuration:
      kafka.input.topics: logisland-mock-out
      kafka.output.topics: none
      kafka.error.topics: none
      index: centralisation
      type: traker1
      hosts: localhost:9300
      batch.size: 200
      timebased.index: yesterday
      es.index.field: es_index

  # Generate random events based on an avro schema
  - component: com.hurence.logisland.parser.apache.ApacheLogParser
    type: parser
    version: 0.1.0
    documentation: a parser that produce events from a REGEX
    configuration:
      kafka.input.topics: logisland-mock-in
      kafka.output.topics: logisland-mock-out
      kafka.error.topics: logisland-error
      event.type: log_traker
      key.regex: (\S*):(\S*)
      key.fields: es_index,host_name